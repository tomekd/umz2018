{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost: eXtreme Gradient Boost "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na dzisiejszych zajęciach będziemy pracować z klasyfikatorem XGBoost, który jest obecnie powszechnie używany."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**zad. 0** Zainstaluj pakiet `xgboost`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**zad. 1** Zaimportuj pakiet `xgboost` jako `xgb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**zad. 2** Zaimportuj poniższe biblioteki."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**zad. 3** Rozpakuj skompresowany plik `train.csv.gz`. Wczytaj za pomocą pandasa powstały plik do zmiennej `data`. Ponadto ustaw klucz na pierwszą kolumne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**zad. 4** Przypisz do zmiennej `y` kolumnę `SalePrice`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-hot Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Część algorytmów jest w stanie obsłużyć tylko dane składające się z samych liczb. Stąd dane, które przyjmują wartości nie liczbowe należy przetworzyć dzięki tzw. *one-hot encoding*. Powiedzmy, że mamy czynnik (kolumnę), który przyjmuje tylko 5 wartości (np. kolorów). Kolory z natury nie da się uporządkość w żaden logiczny sposób i dlatego przypisanie wartości liczbowych byłoby błędem. Stąd, jak w naszym przykładzie, dla każdego koloru tworzymy dodatkową kolumnę i uzupełniamy jedynką tą kolumnę, która odpowiada danej wartości. W Pandasie służy do tego metoda `get_dummies`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies = data['Neighborhood'].str.get_dummies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dodajmy prefiks `Neighborhood_` do każdej kolumny z `dummies`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies.columns = [\"Neighborhood_\" + col for col in dummies.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dołączamy nowe kolumny do `data` i usuwamy kolumnę `Neighborhood`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([data, dummies], axis=1)\n",
    "data = data.drop(\"Neighborhood\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**zad. 5** Napisz funkcję `cat_to_columns(data, column)`, która zautomatyzuje powyższy proces. Argument data to `DataFrame`, zaś `column` to nazwa kolumny, którą chcemy zamienić."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_to_columns(data, column):\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**zad. 6** Sprawdź dzianie na poniższych wartościach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = cat_to_columns(data, \"HouseStyle\")\n",
    "data = cat_to_columns(data, \"BldgType\")\n",
    "data = cat_to_columns(data, \"MSZoning\")\n",
    "data = cat_to_columns(data, \"PavedDrive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    " 'MSSubClass',\n",
    " 'LotFrontage',\n",
    " 'LotArea',\n",
    " 'OverallQual',\n",
    " 'OverallCond',\n",
    " 'YearBuilt',\n",
    " 'GrLivArea',\n",
    " 'BsmtFullBath',\n",
    " 'BsmtHalfBath',\n",
    " 'FullBath',\n",
    " 'HalfBath',\n",
    " 'BedroomAbvGr',\n",
    " 'Fireplaces',\n",
    " 'GarageArea']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stwórz zmienną `X` i przypisz do niej wszystkie kolumny z zmiennej `columns` i wszystkie nowo powstałe kolumny z poprzedniego zadania (plus te, które powstały z kolumny `Neighborhood`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**zad. 7** Podaj ile mamy przykładów trenujących i liczbę zmiennych objaśniających (kolumn)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dzielimy zbiór danych na zbiór treningowy i testowy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tworzymy i trenujemy klasyfikator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_reg = xgb.XGBRegressor(objective=\"reg:linear\", booster=\"gblinear\", seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predykcja na zbiorze testowym:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = xg_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**zad. 8** Oblicz `RMSE` dla danej predykcji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**zad. 9** Dla porównania zbuduj model regresji liniowej i sprawdź, który model działa lepiej."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**zad. 10** zmień parametr `booster` na wartość `gbtree`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inny sposób trenowania modelu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "%matplotlib inline\n",
    "\n",
    "housing_dmatrix = xgb.DMatrix(data=X, label=y)\n",
    "\n",
    "params = {\"objective\":\"reg:linear\", \"max_depth\":2}\n",
    "\n",
    "xg_reg = xgb.train(params=params, dtrain=housing_dmatrix, num_boost_round=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wyświetlnie wytrenowanych drzew:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot the first tree\n",
    "xgb.plot_tree(xg_reg, num_trees=0)\n",
    "\n",
    "fig = matplotlib.pyplot.gcf()\n",
    "fig.set_size_inches(15, 10)\n",
    "plt.show()\n",
    "\n",
    "# Plot the fifth tree\n",
    "xgb.plot_tree(xg_reg, num_trees=4)\n",
    "fig = matplotlib.pyplot.gcf()\n",
    "fig.set_size_inches(15, 10)\n",
    "plt.show()\n",
    "\n",
    "# Plot the last tree sideways\n",
    "xgb.plot_tree(xg_reg, num_trees=9, rankdir='LR')\n",
    "fig = matplotlib.pyplot.gcf()\n",
    "fig.set_size_inches(15, 10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wykres wazności cech:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the DMatrix: housing_dmatrix\n",
    "housing_dmatrix = xgb.DMatrix(data=X, label=y)\n",
    "\n",
    "# Create the parameter dictionary: params\n",
    "params = {\"objective\": \"reg:linear\", \"max_depth\": 4}\n",
    "\n",
    "# Train the model: xg_reg\n",
    "xg_reg = xgb.train(dtrain=housing_dmatrix, num_boost_round=10, params=params)\n",
    "\n",
    "# Plot the feature importances\n",
    "xgb.plot_importance(xg_reg)\n",
    "fig = matplotlib.pyplot.gcf()\n",
    "fig.set_size_inches(15, 10)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Walidacja krzyżowa:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the DMatrix: housing_dmatrix\n",
    "housing_dmatrix = xgb.DMatrix(data=X, label=y)\n",
    "\n",
    "# Create the parameter dictionary: params\n",
    "params = {\"objective\":\"reg:linear\", \"max_depth\":4}\n",
    "\n",
    "# Perform cross-validation: cv_results\n",
    "cv_results = xgb.cv(dtrain=housing_dmatrix, params=params, nfold=4, num_boost_round=5, metrics=\"rmse\", as_pandas=True, seed=123)\n",
    "\n",
    "# Extract and print final boosting round metric\n",
    "print(cv_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Grid search* jest podstawową techniką szukania hiperparametrów. Polega ona na sprawdzenieu wszystkich kombinacji wartości, które chcemy przetestować. W poniższym przykładzie chcemy znaleźć optymalne parametry dla trzech parametrów:  `colsample_bytree`, `n_estimators`, `max_depth`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# Create your housing DMatrix: housing_dmatrix\n",
    "housing_dmatrix = xgb.DMatrix(data=X, label=y)\n",
    "\n",
    "# Create the parameter grid: gbm_param_grid\n",
    "gbm_param_grid = {\n",
    "    'colsample_bytree': [0.3, 0.7],\n",
    "    'n_estimators': [50],\n",
    "    'max_depth': [2, 5]\n",
    "}\n",
    "\n",
    "# Instantiate the regressor: gbm\n",
    "gbm = xgb.XGBRegressor()\n",
    "\n",
    "# Perform grid search: grid_mse\n",
    "grid_mse = GridSearchCV(param_grid=gbm_param_grid, estimator=gbm, scoring=\"neg_mean_squared_error\", cv=4, verbose=1)\n",
    "\n",
    "\n",
    "# Fit grid_mse to the data\n",
    "grid_mse.fit(X, y)\n",
    "\n",
    "\n",
    "# Print the best parameters and lowest RMSE\n",
    "print(\"Best parameters found: \", grid_mse.best_params_)\n",
    "print(\"Lowest RMSE found: \", np.sqrt(np.abs(grid_mse.best_score_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gratulacje!** Skończyłeś zadania na dzisiejsze zajęcia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
